{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from data_loader import *\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from train_utils import *\n",
    "import pickle as pkl\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Choose a config file')\n",
    "\n",
    "# # experiment\n",
    "# parser.add_argument(\n",
    "#     '--experiment',\n",
    "#     default='dummy',\n",
    "#     help='Choose a config file (default: \\'base\\')'\n",
    "# )\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # grab values from arguments\n",
    "# experiment = args.experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if experiment == \"base1\":\n",
    "#     import base1_config as cfg\n",
    "#     from base_model import BaseCaptioner as Model\n",
    "# else:\n",
    "#     import dummy_config as cfg\n",
    "#     from base_model import BaseCaptioner as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cfg = cfg.cfg\n",
    "from base_model import BaseModel as Model\n",
    "batch_size = 20\n",
    "valid_batch_size = 20\n",
    "num_workers = 1\n",
    "epochs = 1\n",
    "model_type = \"dummy\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tr5534_data = pkl.load(open(\"TR5534.pkl\", \"rb\"))\n",
    "cb513_data = pkl.load(open(\"CB513.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_train = len(tr5534_data)\n",
    "percent_train = .8\n",
    "\n",
    "train_start = 0\n",
    "train_end = int(len_train * percent_train)\n",
    "\n",
    "val_start = train_end\n",
    "val_end = len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = np.random.choice(len_train, len_train, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5926"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377 377 154\n"
     ]
    }
   ],
   "source": [
    "train_loader, len_train = get_loader(protein_data=tr5534_data,\n",
    "                                     id_range=[0, 2],\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=num_workers)\n",
    "\n",
    "val_loader, len_val = get_loader(protein_data=tr5534_data,\n",
    "                                 id_range=[0, 2],\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=num_workers)\n",
    "\n",
    "test_loader, len_test = get_loader(protein_data=cb513_data,\n",
    "                                   id_range=[0, 2],\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=num_workers)\n",
    "\n",
    "print(len_train, len_val, len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(model_type):\n",
    "    os.mkdir(model_type)\n",
    "    \n",
    "latest_model_path = os.path.join(model_type, \"latest_model.pt\")\n",
    "best_model_path = os.path.join(model_type, \"best_model.pt\")\n",
    "optim_path = os.path.join(model_type, \"optim.pt\")\n",
    "stats_path = os.path.join(model_type, \"stats.pkl\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init._kaiming_(m.weight.data)\n",
    "\n",
    "\n",
    "        # ??? https://github.com/pytorch/pytorch/issues/3418\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "            # torch.nn.init.xavier_uniform(m.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Model().cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[-1/1], Batch[0/19], Batch Validation Loss: 2.017148494720459\n",
      "Epoch[-1/1], Batch[1/19], Batch Validation Loss: 2.045464038848877\n",
      "Epoch[-1/1], Batch[2/19], Batch Validation Loss: 2.011828660964966\n",
      "Epoch[-1/1], Batch[3/19], Batch Validation Loss: 2.052609920501709\n",
      "Epoch[-1/1], Batch[4/19], Batch Validation Loss: 2.021050214767456\n",
      "Epoch[-1/1], Batch[5/19], Batch Validation Loss: 2.0986149311065674\n",
      "Epoch[-1/1], Batch[6/19], Batch Validation Loss: 2.1079375743865967\n",
      "Epoch[-1/1], Batch[7/19], Batch Validation Loss: 2.0164437294006348\n",
      "Epoch[-1/1], Batch[8/19], Batch Validation Loss: 2.091989278793335\n",
      "Epoch[-1/1], Batch[9/19], Batch Validation Loss: 2.0148186683654785\n",
      "Epoch[-1/1], Batch[10/19], Batch Validation Loss: 2.029604196548462\n",
      "Epoch[-1/1], Batch[11/19], Batch Validation Loss: 2.015789747238159\n",
      "Epoch[-1/1], Batch[12/19], Batch Validation Loss: 2.0420920848846436\n",
      "Epoch[-1/1], Batch[13/19], Batch Validation Loss: 2.0278494358062744\n",
      "Epoch[-1/1], Batch[14/19], Batch Validation Loss: 2.0234696865081787\n",
      "Epoch[-1/1], Batch[15/19], Batch Validation Loss: 2.0323400497436523\n",
      "Epoch[-1/1], Batch[16/19], Batch Validation Loss: 2.0679495334625244\n",
      "Epoch[-1/1], Batch[17/19], Batch Validation Loss: 2.0309202671051025\n",
      "Epoch[-1/1], Batch[18/19], Batch Validation Loss: 2.1083602905273438\n",
      "Total Validation Loss: 2.044563753851529\n",
      "Epoch[0/1], Batch[0/19], Train Loss: 2.0646800994873047\n",
      "Epoch[0/1], Batch[10/19], Train Loss: 1.6785110235214233\n",
      "\n",
      "Finished Epoch 0, Time elapsed: 28.569636344909668, Loss: 1.5514988244686583\n",
      "Epoch[0/1], Batch[0/19], Batch Validation Loss: 1.4311516284942627\n",
      "Epoch[0/1], Batch[1/19], Batch Validation Loss: 1.3940480947494507\n",
      "Epoch[0/1], Batch[2/19], Batch Validation Loss: 1.3924816846847534\n",
      "Epoch[0/1], Batch[3/19], Batch Validation Loss: 1.2340515851974487\n",
      "Epoch[0/1], Batch[4/19], Batch Validation Loss: 1.4267892837524414\n",
      "Epoch[0/1], Batch[5/19], Batch Validation Loss: 1.5380229949951172\n",
      "Epoch[0/1], Batch[6/19], Batch Validation Loss: 1.5596040487289429\n",
      "Epoch[0/1], Batch[7/19], Batch Validation Loss: 1.8053573369979858\n",
      "Epoch[0/1], Batch[8/19], Batch Validation Loss: 1.8349891901016235\n",
      "Epoch[0/1], Batch[9/19], Batch Validation Loss: 1.462733507156372\n",
      "Epoch[0/1], Batch[10/19], Batch Validation Loss: 1.382416009902954\n",
      "Epoch[0/1], Batch[11/19], Batch Validation Loss: 1.4939191341400146\n",
      "Epoch[0/1], Batch[12/19], Batch Validation Loss: 1.2050254344940186\n",
      "Epoch[0/1], Batch[13/19], Batch Validation Loss: 1.2605845928192139\n",
      "Epoch[0/1], Batch[14/19], Batch Validation Loss: 1.6173642873764038\n",
      "Epoch[0/1], Batch[15/19], Batch Validation Loss: 1.3440998792648315\n",
      "Epoch[0/1], Batch[16/19], Batch Validation Loss: 1.7083457708358765\n",
      "Epoch[0/1], Batch[17/19], Batch Validation Loss: 1.3898088932037354\n",
      "Epoch[0/1], Batch[18/19], Batch Validation Loss: 1.7309314012527466\n",
      "Total Validation Loss: 1.4828692333135427\n"
     ]
    }
   ],
   "source": [
    "stats_dict, model = train(1, model, stats_path, train_loader, val_loader, optimizer, criterion,\n",
    "                          len_train, len_val, latest_model_path, best_model_path, optim_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panoptic",
   "language": "python",
   "name": "panoptic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
