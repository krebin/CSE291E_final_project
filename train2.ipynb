{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from data_loader import *\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "from train_utils import *\n",
    "import pickle as pkl\n",
    "import time\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "import csv\n",
    "import torch.nn as nn\n",
    "np.random.seed(42)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import argparse\n",
    "# parser = argparse.ArgumentParser(description='Choose a config file')\n",
    "\n",
    "# # experiment\n",
    "# parser.add_argument(\n",
    "#     '--experiment',\n",
    "#     default='dummy',\n",
    "#     help='Choose a config file (default: \\'base\\')'\n",
    "# )\n",
    "\n",
    "\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# # grab values from arguments\n",
    "# experiment = args.experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if experiment == \"base1\":\n",
    "#     import base1_config as cfg\n",
    "#     from base_model import BaseCaptioner as Model\n",
    "# else:\n",
    "#     import dummy_config as cfg\n",
    "#     from base_model import BaseCaptioner as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cfg = cfg.cfg\n",
    "from base_model import BaseModel as Model\n",
    "batch_size = 5\n",
    "valid_batch_size = 20\n",
    "num_workers = 1\n",
    "epochs = 1\n",
    "model_type = \"dummy\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tr5534_data = pkl.load(open(\"TR5534.pkl\", \"rb\"))\n",
    "cb513_data = pkl.load(open(\"CB513.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len_train = len(cb513_data)\n",
    "percent_train = .8\n",
    "\n",
    "train_start = 0\n",
    "train_end = int(len_train * percent_train)\n",
    "\n",
    "val_start = train_end\n",
    "val_end = len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ids = np.random.choice(len_train, len_train, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "514"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking 0/2 proteins\n",
      "Stacking 250/2 proteins\n",
      "Stacking 500/2 proteins\n",
      "514 514 514\n",
      "Stacking 0/2 proteins\n",
      "Stacking 250/2 proteins\n",
      "Stacking 500/2 proteins\n",
      "514 514 514\n",
      "Stacking 0/2 proteins\n",
      "Stacking 250/2 proteins\n",
      "Stacking 500/2 proteins\n",
      "514 514 514\n",
      "514 514 514\n"
     ]
    }
   ],
   "source": [
    "train_loader, len_train = get_loader(protein_data=cb513_data,\n",
    "                                     ids=[0, 2],\n",
    "                                     batch_size=batch_size,\n",
    "                                     shuffle=True,\n",
    "                                     num_workers=num_workers)\n",
    "\n",
    "val_loader, len_val = get_loader(protein_data=cb513_data,\n",
    "                                 ids=[0, 2],\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=True,\n",
    "                                 num_workers=num_workers)\n",
    "\n",
    "test_loader, len_test = get_loader(protein_data=cb513_data,\n",
    "                                   ids=[0, 2],\n",
    "                                   batch_size=batch_size,\n",
    "                                   shuffle=True,\n",
    "                                   num_workers=num_workers)\n",
    "\n",
    "print(len_train, len_val, len_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latest_model_path = os.path.join(model_type, \"latest_model.pt\")\n",
    "best_model_path = os.path.join(model_type, \"best_model.pt\")\n",
    "optim_path = os.path.join(model_type, \"optim.pt\")\n",
    "stats_path = os.path.join(model_type, \"stats.pkl\")\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        torch.nn.init._kaiming_(m.weight.data)\n",
    "\n",
    "\n",
    "        # ??? https://github.com/pytorch/pytorch/issues/3418\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "            # torch.nn.init.xavier_uniform(m.bias.data)\n",
    "            \n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_1d_3 = nn.Conv1d(in_channels=51, out_channels=100, stride=1, kernel_size=3, padding=1, bias=True).cuda()\n",
    "cnn_1d_5 = nn.Conv1d(in_channels=51, out_channels=100, stride=1, kernel_size=5, padding=2, bias=True).cuda()\n",
    "gru_f_1 = nn.GRU(input_size=251, hidden_size=250, num_layers=1, batch_first=True).cuda()\n",
    "gru_b_1 = nn.GRU(input_size=251, hidden_size=250, num_layers=1, batch_first=True).cuda()\n",
    "\n",
    "gru_f_2 = nn.GRU(input_size=500, hidden_size=500, num_layers=1, batch_first=True).cuda()\n",
    "gru_b_2 = nn.GRU(input_size=500, hidden_size=500, num_layers=1, batch_first=True).cuda()\n",
    "\n",
    "gru_f_3 = nn.GRU(input_size=500, hidden_size=500, num_layers=1, batch_first=True).cuda()\n",
    "gru_b_3 = nn.GRU(input_size=500, hidden_size=500, num_layers=1, batch_first=True).cuda()\n",
    "\n",
    "cnn_1d_1_1 = nn.Conv1d(in_channels=751, out_channels=500, stride=1, kernel_size=1, bias=True).cuda()\n",
    "cnn_1d_1_2 = nn.Conv1d(in_channels=1000, out_channels=500, stride=1, kernel_size=1, bias=True).cuda()\n",
    "\n",
    "fc1 = nn.Linear(500, 1024).cuda()\n",
    "fc2 = nn.Linear(1024, 9).cuda()\n",
    "\n",
    "embedding = nn.Embedding(22, 22).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def forward(x):\n",
    "    one_hot = x[:, 0:22, :].argmax(axis=1)\n",
    "    embedded = embedding(one_hot.long()).permute(0, 2, 1)\n",
    "    x[:, 0:22, :] = embedded\n",
    "    \n",
    "    local_block_3 = cnn_1d_3(x)\n",
    "    local_block_5 = cnn_1d_5(x)\n",
    "    x = nn.functional.relu(torch.cat((x, local_block_3, local_block_5), dim=1))\n",
    "    x = x.permute(0, 2, 1)\n",
    "    \n",
    "    \n",
    "    T = x.shape[1]\n",
    "    h_t_f = torch.zeros(1, x.shape[0], 250).cuda()\n",
    "    h_t_b = torch.zeros(1, x.shape[0], 250).cuda()\n",
    "\n",
    "    h_f = []\n",
    "    h_b = []\n",
    "    \n",
    "    \n",
    "    for t in range(T):\n",
    "        input_t_f = x[:, t, :].unsqueeze(1)\n",
    "        input_t_b = x[:, t, :].unsqueeze(1)\n",
    "        \n",
    "        _, h_t_f = gru_f_1(input_t_f, h_t_f)\n",
    "        _, h_t_b = gru_b_1(input_t_b, h_t_b)\n",
    "\n",
    "        h_f.append(h_t_f)\n",
    "        h_b.append(h_t_b)\n",
    "\n",
    "\n",
    "    F = torch.cat(h_f, dim=2)\n",
    "    B = torch.cat(h_b, dim=2)\n",
    "    O1 = torch.cat((F, B), dim=2).view((x.shape[0], 700, -1))\n",
    "    \n",
    "    \n",
    "    x = torch.cat((x, O1), dim=2)\n",
    "\n",
    "    x = nn.functional.relu(cnn_1d_1_1(x.view([-1, 751, 700])))\n",
    "\n",
    "\n",
    "    h_t_f = torch.zeros(1, x.shape[0], 500).cuda()\n",
    "    h_t_b = torch.zeros(1, x.shape[0], 500).cuda()\n",
    "\n",
    "    h_f = []\n",
    "    h_b = []\n",
    "\n",
    "    x = x.permute([0, 2, 1])\n",
    "    T = x.shape[1]\n",
    "    for t in range(T):\n",
    "        input_t_f = x[:, t, :].unsqueeze(1)\n",
    "        input_t_b = x[:, t, :].unsqueeze(1)\n",
    "\n",
    "\n",
    "        _, h_t_f = gru_f_2(input_t_f, h_t_f)\n",
    "        _, h_t_b = gru_b_2(input_t_b, h_t_b)\n",
    "\n",
    "        h_f.append(h_t_f)\n",
    "        h_b.append(h_t_b)\n",
    "\n",
    "    F = torch.cat(h_f, dim=2)\n",
    "    B = torch.cat(h_b, dim=2, )\n",
    "    O2 = (F + B).view((x.shape[0], 700, -1))\n",
    "    \n",
    "\n",
    "    x = torch.cat((x, O2), dim=2).permute(0, 2, 1)\n",
    "    x = nn.functional.relu(cnn_1d_1_2(x))\n",
    "    \n",
    "\n",
    "    h_t_f = torch.zeros(1, x.shape[0], 500).cuda()\n",
    "    h_t_b = torch.zeros(1, x.shape[0], 500).cuda()\n",
    "\n",
    "    h_f = []\n",
    "    h_b = []\n",
    "    \n",
    "    x = x.permute([0, 2, 1])\n",
    "    T = x.shape[1]\n",
    "    \n",
    "    for t in range(T):\n",
    "        input_t_f = x[:, t, :].unsqueeze(1)\n",
    "        input_t_b = x[:, t, :].unsqueeze(1)\n",
    "\n",
    "\n",
    "        _, h_t_f = gru_f_3(input_t_f, h_t_f)\n",
    "        _, h_t_b = gru_b_3(input_t_b, h_t_b)\n",
    "\n",
    "        h_f.append(h_t_f)\n",
    "        h_b.append(h_t_b)\n",
    "        \n",
    "    F = torch.cat(h_f, dim=2)\n",
    "    B = torch.cat(h_b, dim=2)\n",
    "    x = (F + B).view([x.shape[0], 700, 500])\n",
    "    \n",
    "    x = fc1(x)\n",
    "    x = nn.functional.relu(x)\n",
    "    x = fc2(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 51, 700])\n",
      "torch.Size([5, 700, 9])\n",
      "torch.Size([5, 700, 9]) torch.Size([5, 700, 9])\n",
      "(5, 700)\n",
      "torch.Size([5, 700, 9])\n",
      "933 933 933\n"
     ]
    }
   ],
   "source": [
    "all_labels = []\n",
    "all_preds = []\n",
    "for iter, (X, Y, seq_lens) in enumerate(train_loader):\n",
    "    seq_lens = seq_lens.numpy()\n",
    "    x = X.view([-1, 51, 700]).cuda()\n",
    "    Y = Y.view([-1, 700, 9])\n",
    "\n",
    "    out = forward(x)\n",
    "    print(Y.shape)\n",
    "    targets = Y.argmax(dim=1).long().cuda()\n",
    "    print(out.shape, Y.shape)\n",
    "#     loss = criterion(out, targets)\n",
    "    labels = Y.argmax(dim=2).cpu().numpy()\n",
    "    print(labels.shape)\n",
    "    predictions = out.argmax(axis=2).cpu().numpy()\n",
    "    print(out.shape)\n",
    "    \n",
    "    \n",
    "    for label, prediction, length in zip(labels, predictions, seq_lens):\n",
    "        all_labels += list(label[:length])\n",
    "        all_preds += list(prediction[:length])\n",
    "        \n",
    "    print(len(all_labels), sum(seq_lens), len(all_preds))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = torch.ones((20, 50, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_hot = X[:, 0:21, 0].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model = Model().cuda()\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stats_dict, model = train(1, model, stats_path, train_loader, val_loader, optimizer, criterion,\n",
    "#                           len_train, len_val, latest_model_path, best_model_path, optim_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "panoptic",
   "language": "python",
   "name": "panoptic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
